#!/bin/bash
"""
Quick GPU Usage Check for StockAnalyzer
=======================================
Simple script to verify if GPU is being used by StockAnalyzer
"""

echo "üîç StockAnalyzer GPU Usage Check"
echo "================================="
echo ""

# Check if NVIDIA GPU is available
if ! command -v nvidia-smi &> /dev/null; then
    echo "‚ùå nvidia-smi not found. GPU monitoring not available."
    echo "   Please ensure NVIDIA drivers are installed."
    exit 1
fi

echo "üìä Current GPU Status:"
echo "====================="
nvidia-smi --query-gpu=name,utilization.gpu,memory.used,memory.total --format=csv

echo ""
echo "üî• GPU Processes (looking for Ollama/Python):"
echo "=============================================="
gpu_processes=$(nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv)
if [ -n "$gpu_processes" ]; then
    echo "$gpu_processes"
else
    echo "No active GPU processes found"
fi

echo ""
echo "üöÄ Quick Assessment:"
echo "==================="

# Get current stats
GPU_UTIL=$(nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader,nounits | tr -d ' ')
MEM_USED=$(nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits | tr -d ' ')
MEM_TOTAL=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | tr -d ' ')
PROCESSES=$(nvidia-smi --query-compute-apps=process_name --format=csv,noheader 2>/dev/null | wc -l)

# Calculate memory percentage
if [ "$MEM_TOTAL" -gt "0" ]; then
    MEM_PERCENT=$(echo "$MEM_USED $MEM_TOTAL" | awk '{print int($1*100/$2)}')
else
    MEM_PERCENT=0
fi

echo "GPU Utilization: ${GPU_UTIL}%"
echo "GPU Memory: ${MEM_USED}MB / ${MEM_TOTAL}MB (${MEM_PERCENT}%)"
echo "Active Processes: $PROCESSES"

echo ""
echo "üìã Status Summary:"
echo "=================="

# Determine overall status
if [ "$GPU_UTIL" -gt "15" ] && [ "$MEM_USED" -gt "2000" ]; then
    echo "‚úÖ EXCELLENT: GPU IS ACTIVELY PROCESSING AI WORKLOADS"
    echo "   ‚Üí GPU utilization: ${GPU_UTIL}% (High)"
    echo "   ‚Üí Memory usage: ${MEM_USED}MB (Ollama model loaded)"
    echo "   ‚Üí StockAnalyzer is using GPU acceleration! üöÄ"
elif [ "$GPU_UTIL" -gt "5" ] || [ "$MEM_USED" -gt "1000" ]; then
    echo "üíõ GOOD: GPU IS BEING USED"
    echo "   ‚Üí GPU utilization: ${GPU_UTIL}%"
    echo "   ‚Üí Memory usage: ${MEM_USED}MB"
    echo "   ‚Üí Some GPU processing detected"
elif [ "$PROCESSES" -gt "0" ]; then
    echo "‚ö†Ô∏è  PARTIAL: GPU PROCESSES DETECTED BUT LOW USAGE"
    echo "   ‚Üí GPU utilization: ${GPU_UTIL}%"
    echo "   ‚Üí Memory usage: ${MEM_USED}MB"
    echo "   ‚Üí Check if StockAnalyzer is actively processing"
else
    echo "‚ùå IDLE: GPU NOT CURRENTLY BEING USED"
    echo "   ‚Üí GPU utilization: ${GPU_UTIL}%"
    echo "   ‚Üí Memory usage: ${MEM_USED}MB"
    echo "   ‚Üí No active GPU processes"
fi

echo ""
echo "üîç Ollama Process Check:"
echo "======================="
if pgrep -f "ollama" > /dev/null; then
    echo "‚úÖ Ollama process is running"
    ollama_gpu=$(nvidia-smi --query-compute-apps=process_name,used_memory --format=csv,noheader | grep -i ollama)
    if [ -n "$ollama_gpu" ]; then
        echo "‚úÖ Ollama is using GPU: $ollama_gpu"
    else
        echo "‚ö†Ô∏è  Ollama running but not using GPU"
    fi
else
    echo "‚ùå Ollama process not found"
fi

echo ""
echo "üí° Monitoring Options:"
echo "====================="
echo "‚Ä¢ Real-time monitoring: ./monitor_gpu_usage.sh"
echo "‚Ä¢ Continuous logging: python3 gpu_performance_logger.py"
echo "‚Ä¢ NVIDIA system info: nvidia-smi"
echo ""
echo "üéØ Expected Values for Active Processing:"
echo "‚Ä¢ GPU Utilization: 20-80%"
echo "‚Ä¢ GPU Memory: 2000-4000MB"
echo "‚Ä¢ Active Processes: 1+ (ollama)"
